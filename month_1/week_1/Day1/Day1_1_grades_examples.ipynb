{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ehGsLL7F3RKW",
        "outputId": "6367e917-445e-400f-ab26-c0dc1b95e615"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best slope (learned): 19.0\n",
            "Predicted grades: [19. 38. 57. 76. 95.]\n"
          ]
        }
      ],
      "source": [
        "import numpy as np  # Import the NumPy library for math and array operations\n",
        "\n",
        "# Input data: number of study hours\n",
        "X = np.array([1, 2, 3, 4, 5])\n",
        "\n",
        "# Output data: the grades that correspond to those study hours\n",
        "Y = np.array([50, 60, 65, 70, 80])\n",
        "\n",
        "# We are trying to find a simple rule: grade = m * hours\n",
        "# \"m\" (the slope) tells us how much the grade increases for each extra study hour\n",
        "\n",
        "# We’ll keep track of the best slope (m) we find so far.\n",
        "best_m = 0\n",
        "best_error = 9999 # Start with a very large number so any real result will be smaller (better)\n",
        "\n",
        "# Try many possible slopes (m values) between 0 and 20, in steps of 0.1\n",
        "for m in np.arange(0, 20, 0.1):\n",
        "\n",
        "    # Use this slope (m) to predict grades for all X values\n",
        "    # Example: if m = 10 → [10, 20, 30, 40, 50]\n",
        "    predictions = m * X\n",
        "\n",
        "    # Compute how far off those predictions are from the actual grades (Y)\n",
        "    # (predictions - Y) gives the difference for each data point\n",
        "    # **2 squares those differences so they’re all positive and big mistakes count more\n",
        "    # np.mean(...) takes the average (mean) of those squared differences\n",
        "    # This number is called the \"Mean Squared Error\" (MSE)\n",
        "    error = np.mean((predictions - Y) ** 2)\n",
        "\n",
        "    # If this slope’s error is smaller than the best one so far,\n",
        "    # save it as the new best slope and best error\n",
        "    if error < best_error:\n",
        "        best_error = error\n",
        "        best_m = m\n",
        "\n",
        "# After trying all possible slopes, print the best one we found\n",
        "print(\"Best slope (learned):\", best_m)\n",
        "\n",
        "# Show the model’s predicted grades using the best slope\n",
        "print(\"Predicted grades:\", best_m * X)\n"
      ]
    }
  ]
}